<!DOCTYPE html>
<html lang ="en">
<head>
    <meta chartset = "UTF-8">
    <<link rel="stylesheet" href="mlData/style.css"/>
    <title>Jack Kingdon</title>
    <script src="p5.js"></script>
</head>
<body>
  <div class="container">
    <div class="top-wrapper">
      <div class="title">
        Devolpment of simple image recognition
        neural network from scratch
      </div>
    </div>
    <div class="middle-wrapper">
      <div class="top-info">
        Since late 2020, with the help of the great Daniel Shiffman aka "the coding train",
        I've been experimenting with trying to make an image recognition neural network from scratch,
        with no keras, pytorch or anything.
      </div>
      <div class="middle-info">
        Unlike most networks built
        now, I had to do the matrix
        multiplication by
        hand (matrixmultiplication.xyz) because I wanted to experiance the nitty gritty nature of a network.
      </div>
      <div class="ml-image-wrapper">
        <img class="ml-image" src="img/ml-screencap.png" alt="">
        <div class="image-caption">
         Getting a 10ish percent
          error rate on MNST data with fairly minimal training.
        </div>
      </div>
    </div>
    <div class="bottom-wrapper">
      <div class="bottom-info">
        This network's original design was heavily "inspired" by Daniel
        Shiffman's toy neural network, although once I got further along I definately was sailing on my own. This is an interesting first ML project considering we live in the age of python libaries that produce incredibly advanced nets with 5 lines of code.
      </div>
    </div>

  </div>
</body>
